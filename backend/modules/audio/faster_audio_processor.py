import os
import tempfile
import logging
from typing import List, Tuple, Dict, Optional
from pydub import AudioSegment
try:
    from faster_whisper import WhisperModel, BatchedInferencePipeline
except ImportError:
    from faster_whisper import WhisperModel
    BatchedInferencePipeline = None

# å°è¯•å¯¼å…¥ torch ä»¥æ£€æµ‹ GPU å¯ç”¨æ€§ï¼›è‹¥ä¸å¯ç”¨åˆ™è®¾ä¸º None
try:
    import torch
except Exception:
    torch = None

# å¯¼å…¥è¿›åº¦æ¡åº“
try:
    from tqdm import tqdm
    tqdm_available = True
    logging.info("âœ… è¿›åº¦æ¡åº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    tqdm_available = False
    logging.warning("âš ï¸ è¿›åº¦æ¡åº“å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æ™®é€šè¾“å‡º")

# å¯¼å…¥ AI æ”¯æŒæ¨¡å—
try:
    from ai_support.ai_support import analyze_transcript
    ai_support_available = True
    logging.info("âœ… AI æ”¯æŒæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    ai_support_available = False
    logging.warning(f"âš ï¸ AI æ”¯æŒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    ai_support_available = False
    logging.warning(f"âš ï¸ åˆå§‹åŒ– AI æ”¯æŒæ¨¡å—æ—¶å‡ºé”™: {e}")

# é…ç½®é€‰é¡¹
generate_ai_summary = True  # æ˜¯å¦ç”Ÿæˆ AI æ€»ç»“


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AudioProcessorConfig:
    """éŸ³é¢‘å¤„ç†å™¨é…ç½®"""
    # æ—¶é—´é…ç½®ï¼ˆæ¯«ç§’ï¼‰
    SEGMENT_LENGTH_MS = 15 * 60 * 1000  # 15åˆ†é’Ÿ
    OVERLAP_MS = 30 * 1000  # 30ç§’
    
    # è¾“å‡ºé…ç½®
    TEMP_AUDIO_FORMAT = "wav"
    OUTPUT_ENCODING = "utf-8"


class LongAudioProcessor:
    """
    é•¿éŸ³é¢‘å¤„ç†å™¨ï¼šå°†é•¿éŸ³é¢‘åˆ†å‰²ä¸ºé‡å çš„ç‰‡æ®µè¿›è¡ŒWhisperè¯†åˆ«ï¼Œ
    å¹¶ä¿æŒåŸå§‹æ—¶é—´æˆ³çš„å‡†ç¡®æ€§ã€‚
    """
    
    def __init__(self, model_size: str = "base", device_override: Optional[str] = None, config: Optional[AudioProcessorConfig] = None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        Args:
            model_size: Whisperæ¨¡å‹å¤§å° (tiny, base, small, medium, large)
            config: è‡ªå®šä¹‰é…ç½®å¯¹è±¡
        """
        try:
            # æ”¯æŒæ‰‹åŠ¨è¦†ç›–è®¾å¤‡ï¼ˆdevice_overrideï¼‰ï¼Œä¾‹å¦‚ç”¨äºåœ¨æ— æ³•è”ç½‘æ—¶å¼ºåˆ¶ä½¿ç”¨ CPU è¿›è¡Œæµ‹è¯•
            device = "cpu"
            if device_override is not None:
                device = device_override
                logger.info(f"å¼ºåˆ¶ä½¿ç”¨è®¾å¤‡: {device}ï¼ˆç”± device_override æŒ‡å®šï¼‰")
            else:
                # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦æœ‰å¯ç”¨ GPUï¼ˆCUDAï¼‰
                if torch is not None:
                    try:
                        if torch.cuda.is_available():
                            device = "cuda"
                            logger.info(f"æ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œä½¿ç”¨è®¾å¤‡: {device}")
                        else:
                            logger.info("æœªæ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œä½¿ç”¨ CPU è¿›è¡Œæ¨ç†")
                    except Exception as e:
                        logger.warning(f"æ£€æŸ¥ CUDA å¯ç”¨æ€§æ—¶å‡ºç°é—®é¢˜: {e}; å°†ä½¿ç”¨ CPU")
                        device = "cpu"
                else:
                    logger.info("æœªå®‰è£… torchï¼Œé»˜è®¤ä½¿ç”¨ CPUï¼ˆè‹¥ Whisper ä¾èµ– torchï¼Œè¿™é‡Œä¼šæŠ›å‡ºé”™è¯¯ï¼‰")

            logger.info(f"æ­£åœ¨åŠ è½½ faster-whisper æ¨¡å‹: {model_size} (device={device})")

            # é€‰æ‹© compute_typeï¼šGPU ä½¿ç”¨ float16ï¼ŒCPU å°è¯• int8ï¼ˆè‹¥ä¸å¯ç”¨å›é€€åˆ° float32ï¼‰
            compute_type = None
            if device == "cuda":
                compute_type = "float16"
            else:
                compute_type = "int8"

            try:
                self.model = WhisperModel(model_size, device=device, compute_type=compute_type)
            except Exception as e:
                logger.warning(f"ä½¿ç”¨ compute_type={compute_type} åŠ è½½æ¨¡å‹å¤±è´¥: {e}; å°è¯•å›é€€åˆ° float32")
                self.model = WhisperModel(model_size, device=device, compute_type="float32")

            # å°è¯•å¯ç”¨ BatchedInferencePipeline ä»¥æ”¯æŒ batch_size (ä»… cuda æœ‰æ•ˆ)
            self.batched_mode = False
            if device == "cuda" and BatchedInferencePipeline is not None:
                try:
                    self.model = BatchedInferencePipeline(model=self.model)
                    self.batched_mode = True
                    logger.info("å·²å¯ç”¨ BatchedInferencePipeline æ‰¹å¤„ç†ä¼˜åŒ–")
                except Exception as e:
                    logger.warning(f"å¯ç”¨æ‰¹å¤„ç†ä¼˜åŒ–å¤±è´¥: {e}")

            # ä¿å­˜è®¾å¤‡ä¿¡æ¯ä»¥å¤‡åç»­ä½¿ç”¨/æ—¥å¿—
            self.device = device
            self.config = config or AudioProcessorConfig()
            logger.info("å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤„ç†å™¨å¤±è´¥: {e}")
            raise
        
    def split_audio_with_overlap(self, audio_path: str) -> List[Tuple[AudioSegment, int]]:
        """
        å°†éŸ³é¢‘åˆ†å‰²ä¸ºé‡å çš„ç‰‡æ®µ
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        Returns:
            List of (audio_segment, start_time_ms) å…ƒç»„
        Raises:
            FileNotFoundError: å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶
            Exception: å½“éŸ³é¢‘åŠ è½½å¤±è´¥æ—¶
        """
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(audio_path):
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        try:
            # åŠ è½½éŸ³é¢‘
            logger.info(f"æ­£åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶: {audio_path}")
            audio = AudioSegment.from_file(audio_path)
            duration_ms = len(audio)
            duration_min = duration_ms / 1000 / 60
            
            logger.info(f"éŸ³é¢‘æ€»æ—¶é•¿: {duration_min:.2f}åˆ†é’Ÿ")
            
            # å¦‚æœéŸ³é¢‘é•¿åº¦å°äºç­‰äºç‰‡æ®µé•¿åº¦ï¼Œç›´æ¥è¿”å›
            if duration_ms <= self.config.SEGMENT_LENGTH_MS:
                logger.info("éŸ³é¢‘é•¿åº¦è¾ƒçŸ­ï¼Œä¸éœ€è¦åˆ†å‰²")
                return [(audio, 0)]
            
            segments = self._perform_audio_segmentation(audio, duration_ms)
            logger.info(f"éŸ³é¢‘åˆ†å‰²å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
            return segments
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘åˆ†å‰²å¤±è´¥: {e}")
            raise
    
    def _perform_audio_segmentation(self, audio: AudioSegment, duration_ms: int) -> List[Tuple[AudioSegment, int]]:
        """
        æ‰§è¡ŒéŸ³é¢‘åˆ†å‰²é€»è¾‘
        """
        segments = []
        start_ms = 0
        
        while start_ms < duration_ms:
            # è®¡ç®—ç»“æŸæ—¶é—´ï¼ˆä¸è¶…è¿‡éŸ³é¢‘æ€»é•¿ï¼‰
            end_ms = min(start_ms + self.config.SEGMENT_LENGTH_MS, duration_ms)
            
            # æå–ç‰‡æ®µ
            segment = audio[start_ms:end_ms]
            segments.append((segment, start_ms))
            
            # æ—¥å¿—è¾“å‡ºç‰‡æ®µä¿¡æ¯
            segment_start_min = start_ms / 1000 / 60
            segment_end_min = (start_ms + len(segment)) / 1000 / 60
            logger.debug(f"ç‰‡æ®µ {len(segments)}: {segment_start_min:.1f}min - {segment_end_min:.1f}min")
            
            # è®¡ç®—ä¸‹ä¸€ä¸ªç‰‡æ®µçš„èµ·å§‹æ—¶é—´ï¼ˆå‡å»é‡å éƒ¨åˆ†ï¼‰
            start_ms = end_ms - self.config.OVERLAP_MS
            
            # å¦‚æœå‰©ä½™éƒ¨åˆ†å°äºç­‰äºé‡å éƒ¨åˆ†ï¼Œåˆ™ç»“æŸ
            if duration_ms - start_ms <= self.config.OVERLAP_MS:
                # å¦‚æœæœ‰å‰©ä½™ï¼Œæ·»åŠ æœ€åä¸€æ®µ
                if start_ms < duration_ms:
                    last_segment = audio[start_ms:duration_ms]
                    segments.append((last_segment, start_ms))
                break
        
        return segments
    
    def transcribe_segment(self, audio_segment: AudioSegment, 
                          segment_start_ms: int) -> Dict:
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘ç‰‡æ®µï¼Œå¹¶è°ƒæ•´æ—¶é—´æˆ³
        Args:
            audio_segment: éŸ³é¢‘ç‰‡æ®µ
            segment_start_ms: ç‰‡æ®µçš„èµ·å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        Returns:
            åŒ…å«è½¬å½•ç»“æœçš„å­—å…¸
        """
        temp_path = None
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(
                suffix=f".{self.config.TEMP_AUDIO_FORMAT}", 
                delete=False
            ) as tmp_file:
                temp_path = tmp_file.name
            
            # å°†éŸ³é¢‘ç‰‡æ®µå¯¼å‡ºä¸ºæŒ‡å®šæ ¼å¼
            audio_segment.export(temp_path, format=self.config.TEMP_AUDIO_FORMAT)
            
            # å‡†å¤‡è½¬å½•å‚æ•°
            transcribe_kwargs = {
                "language": "zh",
                # å¼•å¯¼æ¨¡å‹ä½¿ç”¨æ ‡ç‚¹ã€‚è¿™é‡Œä½¿ç”¨é™ˆè¿°å¥è€ŒéæŒ‡ä»¤ï¼Œæ—¢èƒ½æç¤ºæ ‡ç‚¹åˆèƒ½é¿å…å‘½ä»¤å¼å¹»è§‰
                "initial_prompt": "ç®€ä½“ä¸­æ–‡ï¼Œå¥å­ä¹‹é—´æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œæ–­å¥æ¸…æ™°ã€‚",
                "beam_size": 5,
                "vad_filter": True,
                # æ”¾å®½é™éŸ³é˜ˆå€¼åˆ° 1000msã€‚è¿‡çŸ­çš„é˜ˆå€¼(å¦‚500ms)ä¼šåˆ‡æ–­å¥å­ä¸­é—´çš„åœé¡¿ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ä¸¢å¤±ï¼Œæ¨¡å‹æ— æ³•åˆ¤æ–­æ ‡ç‚¹
                "vad_parameters": dict(min_silence_duration_ms=2000),
                "condition_on_previous_text": False
            }

            # å¦‚æœå¯ç”¨äº† BatchedInferencePipelineï¼Œåˆ™æ·»åŠ  batch_size
            if getattr(self, "batched_mode", False):
                transcribe_kwargs["batch_size"] = 24

            # ä½¿ç”¨ faster_whisper è½¬å½•ï¼ˆè¿”å› segments iterable å’Œ infoï¼‰
            logger.debug(f"æ­£åœ¨è½¬å½•ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            segments_iter, info = self.model.transcribe(temp_path, **transcribe_kwargs)

            segments_list = list(segments_iter)
            segment_start_s = segment_start_ms / 1000.0
     
            # æ„å»ºä¸åŸæ¥å…¼å®¹çš„ result å­—å…¸
            result_segments = []
            for seg in segments_list:
                result_segments.append({
                    "start": seg.start + segment_start_s,
                    "end": seg.end + segment_start_s,
                    "text": seg.text
                })

            result = {
                "text": " ".join([s["text"] for s in result_segments]),
                "segments": result_segments,
                "language": getattr(info, "language", None) if info is not None else None
            }

            logger.debug(f"ç‰‡æ®µè½¬å½•å®Œæˆï¼ŒåŒ…å« {len(result.get('segments', []))} æ¡")
            return result
            
        except Exception as e:
            logger.error(f"è½¬å½•ç‰‡æ®µå¤±è´¥: {e}")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path and os.path.exists(temp_path):
                try:
                    os.unlink(temp_path)
                except Exception as e:
                    logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def merge_transcriptions(self, all_results: List[Dict]) -> Dict:
        """
        åˆå¹¶æ‰€æœ‰è½¬å½•ç»“æœï¼Œå¤„ç†é‡å éƒ¨åˆ†
        Args:
            all_results: æ‰€æœ‰è½¬å½•ç»“æœçš„åˆ—è¡¨
        Returns:
            åˆå¹¶åçš„è½¬å½•ç»“æœ
        """
        if not all_results:
            logger.warning("æ²¡æœ‰è½¬å½•ç»“æœéœ€è¦åˆå¹¶")
            return {"text": "", "segments": []}
        
        if len(all_results) == 1:
            logger.info("ä»…æœ‰ä¸€ä¸ªè½¬å½•ç»“æœï¼Œç›´æ¥è¿”å›")
            return all_results[0]
        
        try:
            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µ
            all_segments = []
            for result in all_results:
                if "segments" in result:
                    all_segments.extend(result["segments"])
            
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            all_segments.sort(key=lambda x: x["start"])
            
            # å¤„ç†é‡å éƒ¨åˆ†
            merged_segments = self._merge_overlapping_segments(all_segments)
            
            # åˆå¹¶æ–‡æœ¬
            full_text = " ".join([seg["text"] for seg in merged_segments])
            
            logger.info(f"åˆå¹¶å®Œæˆï¼Œå…± {len(merged_segments)} ä¸ªç‰‡æ®µ")
            
            return {
                "text": full_text,
                "segments": merged_segments,
                "language": all_results[0].get("language", "unknown")
            }
        except Exception as e:
            logger.error(f"åˆå¹¶è½¬å½•ç»“æœå¤±è´¥: {e}")
            raise
    
    def _merge_overlapping_segments(self, segments: List[Dict]) -> List[Dict]:
        """
        å¤„ç†é‡å çš„è½¬å½•ç‰‡æ®µ
        """
        merged_segments = []
        last_end = 0
        overlap_count = 0
        
        for segment in segments:
            start = segment["start"]
            end = segment["end"]
            
            # å¦‚æœè¿™ä¸ªç‰‡æ®µåœ¨å‰ä¸€ä¸ªç‰‡æ®µç»“æŸåæ‰å¼€å§‹
            if start >= last_end or not merged_segments:
                merged_segments.append(segment)
                last_end = end
            else:
                # è®¡ç®—é‡å 
                overlap = last_end - start
                if overlap > 0:
                    overlap_count += 1
                    logger.debug(f"æ£€æµ‹åˆ°é‡å : {overlap:.2f}ç§’ï¼Œè·³è¿‡æ­¤ç‰‡æ®µ")
        
        if overlap_count > 0:
            logger.info(f"æ£€æµ‹åˆ° {overlap_count} ä¸ªé‡å ç‰‡æ®µï¼Œå·²å¤„ç†")
        
        return merged_segments
    
    def process_long_audio(self, audio_path: str) -> Dict:
        """
        ä¸»å¤„ç†å‡½æ•°ï¼šå¤„ç†é•¿éŸ³é¢‘
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        Returns:
            è½¬å½•ç»“æœå­—å…¸
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹å¤„ç†é•¿éŸ³é¢‘...")
        logger.info("=" * 60)
        
        try:
            # 1. åˆ†å‰²éŸ³é¢‘
            segments = self.split_audio_with_overlap(audio_path)
            
            # 2. è½¬å½•æ¯ä¸ªç‰‡æ®µ
            all_results = []
            for i, (segment, start_time) in enumerate(segments, 1):
                logger.info(f"è½¬å½•ç‰‡æ®µ {i}/{len(segments)} (åŸå§‹æ—¶é—´: {start_time/1000:.1f}s)...")
                result = self.transcribe_segment(segment, start_time)
                all_results.append(result)
            
            # 3. åˆå¹¶ç»“æœ
            logger.info("åˆå¹¶æ‰€æœ‰è½¬å½•ç»“æœ...")
            final_result = self.merge_transcriptions(all_results)
            
            logger.info("=" * 60)
            logger.info("âœ… å¤„ç†å®Œæˆï¼")
            logger.info(f"æ€»è¯†åˆ«æ®µè½æ•°: {len(final_result['segments'])}")
            logger.info(f"æ€»æ–‡æœ¬é•¿åº¦: {len(final_result['text'])} å­—ç¬¦")
            logger.info("=" * 60)
            
            return final_result
            
        except Exception as e:
            logger.error(f"å¤„ç†éŸ³é¢‘å¤±è´¥: {e}")
            raise
    
    def save_transcription_with_timestamps(self, result: Dict, output_path: str) -> None:
        """
        ä¿å­˜å¸¦æ—¶é—´æˆ³çš„è½¬å½•ç»“æœ
        Args:
            result: è½¬å½•ç»“æœå­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(output_path, "w", encoding=self.config.OUTPUT_ENCODING) as f:
                # å†™å…¥æ‘˜è¦ä¿¡æ¯
                f.write(f"# éŸ³é¢‘è½¬å½•ç»“æœ\n")
                f.write(f"è¯­è¨€: {result.get('language', 'æœªçŸ¥')}\n")
                f.write(f"æ€»æ®µè½æ•°: {len(result['segments'])}\n\n")
                
                # å†™å…¥å¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬
                f.write("## æ—¶é—´æˆ³æ–‡æœ¬\n")
                for seg in result["segments"]:
                    time_str = self._format_timestamp_range(seg["start"], seg["end"])
                    f.write(f"\n[{time_str}] {seg['text']}")
            
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è½¬å½•ç»“æœå¤±è´¥: {e}")
            raise
    
    @staticmethod
    def _format_timestamp_range(start: float, end: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³èŒƒå›´"""
        def format_time(seconds: float) -> str:
            minutes = int(seconds // 60)
            secs = seconds % 60
            return f"{minutes:02d}:{secs:06.3f}"
        
        return f"{format_time(start)} - {format_time(end)}"

def process_audio(audio_path: str, model_size: str = "medium", device_override: Optional[str] = None) -> Dict:
    """å¤„ç†éŸ³é¢‘å¹¶ä¿å­˜è½¬å½•ç»“æœã€‚

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_size: Whisper æ¨¡å‹å¤§å°ï¼ˆtiny, base, small, medium, largeï¼‰

    Returns:
        è½¬å½•ç»“æœå­—å…¸
    """
    try:
        # åˆå§‹åŒ–å¤„ç†å™¨
        logger.info("åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨...")
        processor = LongAudioProcessor(model_size=model_size, device_override=device_override)

        result = processor.process_long_audio(audio_path)

        # ç¡®ä¿ output æ–‡ä»¶å¤¹å­˜åœ¨
        output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'output')
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(audio_path))[0]
        output_file = os.path.join(output_dir, f"{base_name}_transcription_with_timestamps.txt")
        processor.save_transcription_with_timestamps(result, output_file)

        # ç”Ÿæˆ AI æ€»ç»“
        if generate_ai_summary and ai_support_available:
            logger.info("=" * 60)
            logger.info("ğŸ¤– å¼€å§‹ç”Ÿæˆ AI æ€»ç»“...")
            logger.info("=" * 60)
            try:
                import time
                start_time = time.time()
                
                # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹
                if tqdm_available:
                    # æ¨¡æ‹Ÿè¿›åº¦æ¡ï¼Œå› ä¸º analyze_transcript æ˜¯ä¸€ä¸ªé˜»å¡è°ƒç”¨
                    with tqdm(total=100, desc="AI å¤„ç†ä¸­", unit="%") as pbar:
                        # åˆå§‹åŒ–
                        pbar.update(10)
                        pbar.set_postfix(status="åˆå§‹åŒ– AI æœåŠ¡")
                        time.sleep(0.5)
                        
                        # å¤„ç†ä¸­
                        pbar.update(30)
                        pbar.set_postfix(status="åˆ†ææ–‡æœ¬å†…å®¹")
                        time.sleep(0.5)
                        
                        # è°ƒç”¨ AI æœåŠ¡
                        pbar.update(40)
                        pbar.set_postfix(status="è°ƒç”¨ AI æ¨¡å‹")
                        summary_result = analyze_transcript(output_file)
                        
                        # å®Œæˆ
                        pbar.update(20)
                        pbar.set_postfix(status="ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
                        time.sleep(0.5)
                else:
                    # æ— è¿›åº¦æ¡æ—¶ç›´æ¥è°ƒç”¨
                    logger.info("å¤„ç†ä¸­...")
                    summary_result = analyze_transcript(output_file)
                
                end_time = time.time()
                elapsed_time = end_time - start_time
                
                logger.info(f"âœ… AI æ€»ç»“ç”ŸæˆæˆåŠŸï¼")
                logger.info(f"â±ï¸  å¤„ç†æ—¶é—´: {elapsed_time:.2f} ç§’")
                logger.info(f"ğŸ“„ æ€»ç»“æ–‡ä»¶: {summary_result.get('output_file', 'æœªçŸ¥')}")
                logger.info(f"ğŸ“Š æ€»ç»“é•¿åº¦: {summary_result.get('summary_length', 0):,} å­—ç¬¦")
                logger.info(f"ğŸ“ˆ åŸå§‹æ–‡æœ¬é•¿åº¦: {summary_result.get('text_length', 0):,} å­—ç¬¦")
                logger.info(f"ğŸ”§ ä½¿ç”¨æ¨¡æ¿: {summary_result.get('template_used', 'æœªçŸ¥')}")
                logger.info(f"ğŸ¤– AI æ¨¡å‹: {summary_result.get('ai_model', 'æœªçŸ¥')}")
                logger.info("=" * 60)
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆ AI æ€»ç»“å¤±è´¥: {e}")
                logger.warning("éŸ³é¢‘è½¬å½•å·²å®Œæˆï¼Œä½† AI æ€»ç»“ç”Ÿæˆå¤±è´¥")
                logger.info("=" * 60)
        elif not generate_ai_summary:
            logger.info("âš ï¸ AI æ€»ç»“ç”Ÿæˆå·²ç¦ç”¨ï¼Œè·³è¿‡æ€»ç»“ç”Ÿæˆ")
        else:
            logger.info("âš ï¸ AI æ”¯æŒæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æ€»ç»“ç”Ÿæˆ")

        logger.info("å‰3ä¸ªç‰‡æ®µç¤ºä¾‹:")
        for i, seg in enumerate(result.get("segments", [])[:3], 1):
            preview = seg.get("text", "")[:50] + ("..." if len(seg.get("text", "")) > 50 else "")
            logger.info(f"  {i}. [{seg.get('start', 0):.2f}s - {seg.get('end', 0):.2f}s]: {preview}")

        return result

    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        raise
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    # ç¤ºä¾‹è°ƒç”¨ï¼šä¿®æ”¹ä¸ºå®é™…éŸ³é¢‘è·¯å¾„å’Œæ‰€éœ€æ¨¡å‹
    sample_audio = "C:\\Users\\15352\\Desktop\\test1\\ç¬¬14è¯¾ ä»·å€¼åº•çº¿ï¼šä»€ä¹ˆæ˜¯â€œä¸‰è§‚ä¸€è‡´â€ï¼Ÿ.mp3"
    
    # é»˜è®¤ï¼šè‡ªåŠ¨æ£€æµ‹ GPUï¼ˆè‹¥å¯ç”¨ï¼‰æˆ–ä½¿ç”¨ CPU
    process_audio(sample_audio, model_size="medium")
    
    # å¼ºåˆ¶ä½¿ç”¨ CPU è¿›è¡Œæµ‹è¯•ï¼ˆç”¨äºè°ƒè¯•æˆ–åœ¨æ— æ³•è”ç½‘çš„ç¯å¢ƒä¸­ï¼‰ï¼š
    # process_audio(sample_audio, model_size="medium", device_override="cpu")
    
    # å¼ºåˆ¶ä½¿ç”¨ GPUï¼š
    # process_audio(sample_audio, model_size="medium", device_override="cuda")